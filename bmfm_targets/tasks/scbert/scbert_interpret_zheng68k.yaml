defaults:
  - base_scbert_config
  - _self_

seed:
  seed_value: 1234

data_module:
  #batch size will be force set to 1 no matter what is requested
  _target_: bmfm_targets.datasets.zheng68k.Zheng68kDataModule
  _partial_: true
  num_workers: 8
  collation_strategy: "sequence_classification"
  max_length: 512
  sequence_order: random
  pad_to_multiple_of: 16
  limit_dataset_samples: 10
  data_dir: ${oc.env:BMFM_TARGETS_ZHENG68K_DATA}
  transform_datasets: false
task:
  #epochs will be force set to 1 no matter what is requested
  _target_: bmfm_targets.config.InterpretTaskConfig
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}
  accelerator: "gpu"
  precision: "16-mixed"
  attribute_kwargs:
    n_steps: 50
  tf32_mode: "medium" # permitted nonNone values of tf32_mode:  "highest","high","medium"
   # fill this in with a post April 9 2024 ckpt or add model, fields and tokenizer sections
  checkpoint: /dccstor/bmfm-targets/users/dmichael/scbert_train/scbert_train_2024-05-10_05-27-19/last.ckpt
