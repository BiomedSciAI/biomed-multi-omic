defaults:
  - base_scbert_config
  - _self_

seed:
  seed_value: 1234

# fields are is supplied outside as it is needed by both data module and model
fields:
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "genes"
    pretrained_embedding: null
    is_masked: true
    decode_modes:
      - token_scores
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "expressions"
    pretrained_embedding: null
    is_masked: true
    decode_modes:
      - token_scores
data_module:
  _target_: bmfm_targets.datasets.panglaodb.PanglaoDBDataModule
  _partial_: true
  num_workers: 8
  mlm: true
  collation_strategy: "language_modeling"
  change_ratio: 0.25
  mask_ratio: 0.8
  switch_ratio: 0.1
  batch_size: 32
  shuffle: true
  limit_dataset_samples: null
  dataset_kwargs:
    data_dir: ${oc.env:BMFM_TARGETS_PANGLAO_DATA}
    data_info_path: ${oc.env:BMFM_TARGETS_PANGLAO_METADATA}
    filter_query: 'Species == "Homo sapiens"'
    num_workers: 8
    transform_datasets: false
    convert_rdata_to_h5ad: false

model:
  _target_: bmfm_targets.config.SCBertConfig
  _partial_: true
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: "gelu"
  hidden_size: 768
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  initializer_range: 0.02
  layer_norm_eps: 1e-12
  pad_token_id: 0
  use_cache: true
  classifier_dropout: 0.1
  checkpoint: null


trainer:
  _target_: bmfm_targets.config.TrainerConfig
  warmup_steps: 1000
  weight_decay: 0.01
  learning_rate: 1.0e-4
  betas:
    - 0.9
    - 0.99
  epsilon: 1.0e-8
  lr_decay_steps: null
  losses:
    - field_name: expressions
      name: cross_entropy
      weight: 1
      label_smoothing: 0.01
    - field_name: expressions
      name: token_value
      weight: 1


task:
  _target_: bmfm_targets.config.TrainingTaskConfig
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}
  max_epochs: 20
  precision: "16-mixed"

  val_check_interval:  0.05
  gradient_clip_val: 0.5
  accelerator: "gpu"
  max_steps: -1  # -1 means no limit
  tf32_mode: null # permitted nonNone values of tf32_mode:  "highest","high","medium"
  accumulate_grad_batches:  1
  freeze_layers: false
  resume_training_from_ckpt: true


track_clearml:
    project_name: "bmfm-targets"
    task_name: "scbert_panglaodb_pretrain"
    continue_last_task: False
