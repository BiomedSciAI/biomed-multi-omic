defaults:
  - _self_

seed:
  seed_value: 1234

tokenizer:
  _target_: bmfm_targets.config.TokenizerConfig
  identifier: all_genes

label_columns:
  - _target_: bmfm_targets.config.LabelColumnInfo
    label_column_name: "celltype"
    is_stratification_label: true

fields:
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "genes"
    is_masked: false
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "expressions"
    is_masked: true
    tokenization_strategy: continuous_value_encoder
    encoder_kwargs:
      kind: scale_adapt
      n_sin_basis: 48
      basis_scale: 1.5
      trainable: true
      zero_as_special_token: true
    decode_modes:
      - "regression"
      - "is_zero"
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "label_expressions"
    is_input: false
    tokenization_strategy: continuous_value_encoder
    decode_modes:
      - "regression"
      - "is_zero"
data_module:
  _target_: bmfm_targets.datasets.zheng68k.Zheng68kDataModule
  _partial_: true
  num_workers: 8
  collation_strategy: "language_modeling"
  mlm: true
  max_length: 1024
  batch_size: 16
  masking_strategy:
    _target_: bmfm_targets.training.masking.adaptive_strategy.AdaptiveMaskingStrategy
    _partial_: true
    use_for_validation: false
    callback:
      _target_: bmfm_targets.training.masking.adaptive_strategy.TokenErrorUpdateCallback
      error_column_name: "gene_err"
      token_level_error_key: null
      n_bins: 100
      error_masking_relation: ${error_masking_relation}
  change_ratio: 0.3
  mask_ratio: 0.95
  switch_ratio: 0.
  pad_to_multiple_of: 16
  rda_transform: "downsample"
  pad_zero_expression_strategy: batch_wise
  shuffle: true
  sequence_order: "sorted"
  dataset_kwargs:
    expose_zeros: all
  data_dir: ${oc.env:BMFM_TARGETS_ZHENG68K_DATA}
  # log_normalize_transform: true
  processed_name: raw_counts #processed_optimized_no_binning
  transform_datasets: false


model:
  _target_: bmfm_targets.config.SCBertConfig
  _partial_: true
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: gelu
  hidden_size: 768
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  initializer_range: 0.02
  layer_norm_eps: 1.0e-12
  use_cache: true
  attention: torch
  # checkpoint: /dccstor/bmfm-targets1/users/dmichael/training_runs/mlm_test2/last-v10.ckpt
  #/dccstor/bmfm-targets1/users/dmichael/training_runs/mlm_test/last-v10.ckpt
# file:///dccstor/bmfm-targets1/users/dmichael/training_runs/mlm_test2/last-v8.ckpt
  #/dccstor/bmfm-targets/models/omics/transcriptome/scRNA/pretrain/bmfm.targets.slate.bert.110m.scRNA.RDA.v1/last-v3.ckpt
  # /dccstor/bmfm-targets1/users/dmichael/scbert_train/scbert_train_2024-09-11_16-09-07/last.ckpt
  #/dccstor/bmfm-targets1/users/dmichael/scbert_train/scbert_train_2024-09-10_09-20-49/last.ckpt
  # /dccstor/bmfm-targets1/users/bdand/training_runs/cellxgene_rda_training_fix_cve_latest/last.ckpt
  #/dccstor/bmfm-targets/users/dmichael/scbert_train/scbert_train_2024-08-20_05-33-18/last.ckpt
  #/dccstor/bmfm-targets/users/dmichael/scbert_train/scbert_train_2024-08-20_04-26-01/last.ckpt

trainer:
  _target_: bmfm_targets.config.TrainerConfig
  weight_decay: null
  learning_rate: 5.0e-6
  betas:
    - 0.9
    - 0.99
  epsilon: 1.0e-8
  lr_decay_steps: null
  batch_prediction_behavior: track
  losses:
    - field_name: expressions
      name: mse
      ignore_zero: true
      # link_function: exp
    - field_name: expressions
      name: is_zero_bce

track_clearml:
    project_name: "bmfm-targets"
    task_name: "scbert_zheng68k_mlm_adaptive_${error_masking_relation}_debug"
    continue_last_task: true

task:
  _target_: bmfm_targets.config.TrainingTaskConfig
  #default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/${track_clearml.task_name}/
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/zheng_mlm_adaptive/
  max_epochs: 200
  precision: "16-mixed"
  val_check_interval:  500
  accelerator: "gpu"
  max_steps: -1  # -1 means no limit
  tf32_mode: "medium" # permitted nonNone values of tf32_mode:  "highest","high","medium"
  accumulate_grad_batches:  4
  freeze_layers: false
  resume_training_from_ckpt: false
error_masking_relation: increasing
