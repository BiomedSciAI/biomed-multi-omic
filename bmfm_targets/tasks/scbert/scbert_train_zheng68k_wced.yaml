defaults:
  - base_scbert_config
  - _self_

seed:
  seed_value: 1234

tokenizer:
  _target_: bmfm_targets.config.TokenizerConfig
  identifier: protein_coding

label_columns:
  - _target_: bmfm_targets.config.LabelColumnInfo
    label_column_name: "celltype"
    is_stratification_label: true

fields:
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "genes"
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "expressions"
    is_masked: false
    tokenization_strategy: continuous_value_encoder
    encoder_kwargs:
      kind: "mlp_with_special_token_embedding"
      zero_as_special_token: true
    decode_modes:
      wced:
        vocab_field: genes
        logit_outputs:
          - mse
          - is_zero_bce

data_module:
  _target_: bmfm_targets.datasets.zheng68k.Zheng68kDataModule
  _partial_: true
  num_workers: 8
  collation_strategy: "language_modeling"
  mlm: true
  max_length: 256
  batch_size: 16
  masking_strategy:
   _target_: bmfm_targets.training.masking.WCEDMasker
   _partial_: true
  change_ratio: 0.3
  mask_ratio: 0.95
  switch_ratio: 0.
  pad_to_multiple_of: 16
  log_normalize_transform: true
  pad_zero_expression_strategy: batch_wise
  shuffle: true
  sequence_order: "random"
  dataset_kwargs:
    expose_zeros: all
  data_dir: ${oc.env:BMFM_TARGETS_ZHENG68K_DATA}
  transform_datasets: true


model:
  _target_: bmfm_targets.config.SCBertConfig
  _partial_: true
  num_hidden_layers: 2
  num_attention_heads: 2
  intermediate_size: 128
  hidden_act: gelu
  hidden_size: 128
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  initializer_range: 0.02
  layer_norm_eps: 1.0e-12
  pad_token_id: 2
  use_cache: true
  attention: torch
  # checkpoint: /dccstor/bmfm-targets1/users/dmichael/training_runs/mlm_test2/last-v10.ckpt
  #/dccstor/bmfm-targets1/users/dmichael/training_runs/mlm_test/last-v10.ckpt
# file:///dccstor/bmfm-targets1/users/dmichael/training_runs/mlm_test2/last-v8.ckpt
  #/dccstor/bmfm-targets/models/omics/transcriptome/scRNA/pretrain/bmfm.targets.slate.bert.110m.scRNA.RDA.v1/last-v3.ckpt
  # /dccstor/bmfm-targets1/users/dmichael/scbert_train/scbert_train_2024-09-11_16-09-07/last.ckpt
  #/dccstor/bmfm-targets1/users/dmichael/scbert_train/scbert_train_2024-09-10_09-20-49/last.ckpt
  # /dccstor/bmfm-targets1/users/bdand/training_runs/cellxgene_rda_training_fix_cve_latest/last.ckpt
  #/dccstor/bmfm-targets/users/dmichael/scbert_train/scbert_train_2024-08-20_05-33-18/last.ckpt
  #/dccstor/bmfm-targets/users/dmichael/scbert_train/scbert_train_2024-08-20_04-26-01/last.ckpt

trainer:
  _target_: bmfm_targets.config.TrainerConfig
  weight_decay: null
  learning_rate: 5.0e-6
  betas:
    - 0.9
    - 0.99
  epsilon: 1.0e-8
  lr_decay_steps: null
  batch_prediction_behavior: track
  losses:

    - field_name: expressions
      name: mse
      ignore_zero: true
      wced_target: input_genes
    - field_name: expressions
      name: is_zero_bce
      wced_target: input_genes

    - field_name: expressions
      name: mse
      ignore_zero: true
      wced_target: non_input_genes
    - field_name: expressions
      name: is_zero_bce
      wced_target: non_input_genes

track_clearml:
    project_name: "bmfm-targets"
    task_name: "scbert_zheng68k_wced"

task:
  _target_: bmfm_targets.config.TrainingTaskConfig
  #default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/${track_clearml.task_name}/
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/mlm_test2/
  max_epochs: 200
  precision: "16-mixed"
  # val_check_interval:  500
  accelerator: "gpu"
  max_steps: -1  # -1 means no limit
  tf32_mode: "medium" # permitted nonNone values of tf32_mode:  "highest","high","medium"
  accumulate_grad_batches:  4
  freeze_layers: false
  resume_training_from_ckpt: false
