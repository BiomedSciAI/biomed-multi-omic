defaults:
  - base_scbert_config
  - _self_
seed:
  seed_value: 1234
tokenizer:
  _target_: bmfm_targets.config.TokenizerConfig
  identifier: all_genes
label_columns:
  - _target_: bmfm_targets.config.LabelColumnInfo
    label_column_name: "celltype"
    is_stratification_label: true
fields:
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "genes"
  - _target_: bmfm_targets.config.FieldInfo
    field_name: expressions
    is_masked: false
    tokenization_strategy: continuous_value_encoder
    encoder_kwargs:
      kind: mlp_with_special_token_embedding
      zero_as_special_token: true
    decode_modes:
      wced:
        vocab_field: genes
        logit_outputs:
        - mse
        - is_zero_bce
  - _target_: bmfm_targets.config.FieldInfo
    field_name: label_expressions
    is_input: false
    tokenization_strategy: continuous_value_encoder
    encoder_kwargs:
      kind: mlp_with_special_token_embedding
      zero_as_special_token: true
    decode_modes:
    - regression
    - is_zero
data_module:
  _target_: bmfm_targets.datasets.zheng68k.Zheng68kDataModule
  _partial_: true
  num_workers: 8
  collation_strategy: "language_modeling"
  mlm: true
  max_length: scheduled
  batch_size: scheduled
  drop_last: true
  masking_strategy:
    _target_: bmfm_targets.training.masking.strategy.WCEDMasker
    _partial_: true
    sample_transforms_kwargs:
      median_normalization: false
      log_normalize_transform: true
  change_ratio: 0.3
  mask_ratio: 0.95
  switch_ratio: 0.
  pad_to_multiple_of: 16
  limit_genes: protein_coding
  median_normalization: false
  log_normalize_transform: true
  pad_zero_expression_strategy: batch_wise
  shuffle: true
  sequence_order: "sorted"
  dataset_kwargs:
    expose_zeros: all
  data_dir: ${oc.env:BMFM_TARGETS_ZHENG68K_DATA}
model:
  _target_: bmfm_targets.config.SCBertConfig
  _partial_: true
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: gelu
  hidden_size: 768
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  initializer_range: 0.02
  layer_norm_eps: 1.0e-12
  pad_token_id: 0
  use_cache: true
  attention: torch
  checkpoint: null
trainer:
  _target_: bmfm_targets.config.TrainerConfig
  warmup_steps: 1000
  weight_decay: 0.01
  learning_rate: 0.0001
  betas:
  - 0.9
  - 0.99
  epsilon: 1.0e-08
  lr_decay_steps: null
  losses:
    - field_name: expressions
      name: mse
      ignore_zero: true
      wced_target: non_input_genes
    - field_name: expressions
      name: is_zero_bce
      wced_target: non_input_genes
    - field_name: expressions
      name: mse
      ignore_zero: true
      wced_target: input_genes
    - field_name: expressions
      name: is_zero_bce
      wced_target: input_genes
  batch_prediction_behavior: track
track_clearml:
    project_name: "bmfm-targets"
    task_name: "scbert_zheng68k_wced_dynamic_mixed"
task:
  _target_: bmfm_targets.config.TrainingTaskConfig
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/scbert_zheng68k_wced_dynamic_mixed
  # default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/wced_scheduled/${track_clearml.task_name}/
  max_epochs: 10
  precision: 16-mixed
  accelerator: gpu
  max_steps: -1
  tf32_mode: medium
  accumulate_grad_batches: 4
  freeze_layers: false
  gradient_clip_val: 0.5
  resume_training_from_ckpt: false
  reload_dataloaders_every_n_epochs: 1
  callbacks:
    - _target_: bmfm_targets.training.callbacks.BatchSizeScheduler
      schedule:
        - max_length: 512
          batch_size: 64
        - max_length: 1024
          batch_size: 32
        - max_length: 2048
          batch_size: 16
