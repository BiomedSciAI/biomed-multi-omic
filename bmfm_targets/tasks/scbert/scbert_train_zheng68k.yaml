defaults:
  - base_scbert_config
  - _self_

seed:
  seed_value: 1234

tokenizer:
  _target_: bmfm_targets.config.TokenizerConfig
  identifier: gene2vec

# fields are supplied outside as it is needed by both data module and model
fields:
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "genes"
    pretrained_embedding: null
    is_masked: false
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "expressions"
    pretrained_embedding: null
    is_masked: true
    vocab_update_strategy: dynamic
    decode_modes:
      - token_scores

label_columns:
  - _target_: bmfm_targets.config.LabelColumnInfo
    label_column_name: "celltype"
    is_stratification_label: true

data_module:
  _target_: bmfm_targets.datasets.zheng68k.Zheng68kDataModule
  _partial_: true
  num_workers: 8
  collation_strategy: "sequence_classification"
  batch_size: 20
  max_length: 512
  pad_to_multiple_of: 16
  change_ratio: 0.15
  mask_ratio: 0.5
  switch_ratio: 0.5
  limit_dataset_samples: null
  shuffle: true
  sequence_order: "random"
  data_dir: ${oc.env:BMFM_TARGETS_ZHENG68K_DATA}

model:
  _target_: bmfm_targets.config.SCBertConfig
  _partial_: true
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: "gelu"
  hidden_size: 768
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  initializer_range: 0.02
  layer_norm_eps: 1.0e-12
  pad_token_id: 0
  use_cache: true
  classifier_dropout: 0.1
  checkpoint: /dccstor/bmfm-targets/users/dmichael/scbert_train/scbert_train_2023-12-14_13-52-28/last.ckpt

trainer:
  _target_: bmfm_targets.config.TrainerConfig
  warmup_steps: 0
  weight_decay: null
  learning_rate: 1.0e-5
  betas:
    - 0.9
    - 0.99
  epsilon: 1.0e-8
  lr_decay_steps: null
  losses:
  - label_column_name: celltype

track_clearml:
    project_name: "bmfm-targets"
    task_name: "scbert_zheng68k_fine_tune"
    continue_last_task: False

task:
  _target_: bmfm_targets.config.TrainingTaskConfig
  #default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/${track_clearml.task_name}/
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}
  max_epochs: 20
  precision: "16-mixed"
  val_check_interval:  0.05
  accelerator: "gpu"
  max_steps: -1  # -1 means no limit
  tf32_mode: null # permitted nonNone values of tf32_mode:  "highest","high","medium"
  accumulate_grad_batches:  1
  freeze_layers: false
  resume_training_from_ckpt: false
