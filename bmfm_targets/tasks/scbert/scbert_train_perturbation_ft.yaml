defaults:
  - base_scbert_config
  - _self_

seed:
  seed_value: 1234

tokenizer:
  _target_: bmfm_targets.config.TokenizerConfig
  identifier: all_genes
# fields are supplied outside as it is needed by both data module and model
fields:
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "genes"
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "expressions"
    tokenization_strategy: continuous_value_encoder
    encoder_kwargs:
      kind: mlp_with_special_token_embedding
      zero_as_special_token: true
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "perturbations"
  - _target_: bmfm_targets.config.FieldInfo
    field_name: "label_expressions"
    is_input: false
    tokenization_strategy: continuous_value_encoder
    encoder_kwargs:
      kind: mlp_with_special_token_embedding
      zero_as_special_token: true
    decode_modes:
      - "regression"
      - "is_zero"


data_module:
  _target_: bmfm_targets.datasets.perturbation.ScperturbDataModule
  _partial_: true
  data_dir: ${oc.env:BMFM_TARGETS_ADAMSON_DATA}
  num_workers: 8
  max_length: 4096
  sequence_order: sorted
  batch_size: 8
  collation_strategy: "sequence_labeling"
model:
  _target_: bmfm_targets.config.SCBertConfig
  _partial_: true
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: "gelu"
  hidden_size: 768
  attention: torch
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  initializer_range: 0.02
  layer_norm_eps: 1e-12
  use_cache: true
  checkpoint: /dccstor/bmfm-targets1/users/bdand/training_runs/cellxgene_rda_training_fix_cve_latest/last.ckpt

trainer:
  _target_: bmfm_targets.config.TrainerConfig
  warmup_steps: 0
  weight_decay: 0
  learning_rate: 5.0e-6
  betas:
    - 0.9
    - 0.99
  epsilon: 1.0e-8
  lr_decay_steps: null
  losses:
    - field_name: label_expressions
      name: mse
      ignore_zero: true
      link_function: exp
    - field_name: label_expressions
      name: is_zero_bce

task:
  _target_: bmfm_targets.config.TrainingTaskConfig
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}
  max_epochs: 40
  precision: "16-mixed"
  check_val_every_n_epoch: 1
  val_check_interval: null
  gradient_clip_val: 0.5
  accelerator: "gpu"
  max_steps: -1  # -1 means no limit
  tf32_mode: "medium" # permitted nonNone values of tf32_mode:  "highest","high","medium"
  accumulate_grad_batches:  4
  freeze_layers: false
  resume_training_from_ckpt: false



track_clearml:
    project_name: "bmfm-targets"
    task_name: "scbert_perturbation_ft"
    continue_last_task: false
