{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e18538",
   "metadata": {},
   "source": [
    "# How it works\n",
    "\n",
    "**AnnCollectionDataset** directly reads h5ad files through [AnnCollection](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/anncollection.html) and serve data using [LitData](https://github.com/Lightning-AI/litdata) frontend. To use dataset, we first need to prepare dataset index folder that has multiple splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37610cb",
   "metadata": {},
   "source": [
    "# Building LitData index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb9a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/pandera/engines/pandas_engine.py:67: UserWarning: Using typeguard < 3. Generic types like List[TYPE], Dict[TYPE, TYPE] will only validate the first element in the collection.\n",
      "  warnings.warn(\n",
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/dccstor/bmfm-targets/users/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from bmfm_targets.datasets.anncollection.anncollection_dataset import (\n",
    "    get_ann_collection,\n",
    ")\n",
    "from bmfm_targets.datasets.data_conversion.litdata_indexing import build_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5462d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_folders(h5ad_src, dest_root=None, dest=None):\n",
    "    if dest is None and dest_root is not None:\n",
    "        dest = Path(dest_root) / \"_\".join([l[1] for l in h5ad_src])\n",
    "    else:\n",
    "        dest = Path(dest)\n",
    "    data_dir = dest / \"ALL\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    for elm in h5ad_src:\n",
    "        ln_src = Path(elm[0]) if type(elm) is tuple else Path(elm)\n",
    "        name = f\"{(Path(elm[1]) if type(elm) is tuple else Path(elm)).stem}.h5ad\"\n",
    "        ln_dst = data_dir / name\n",
    "        if os.path.isfile(ln_dst):\n",
    "            os.remove(ln_dst)\n",
    "        os.symlink(ln_src, ln_dst)\n",
    "\n",
    "    index_dir = dest / \"litdata_index\"\n",
    "    os.makedirs(index_dir, exist_ok=True)\n",
    "    #shutil.rmtree(index_dir)\n",
    "    return {\n",
    "        \"index\": index_dir,\n",
    "        \"data\": data_dir,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c801f3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/dccstor/bmfm-targets/data/omics/transcriptome/scRNA/finetune')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_root = Path(\"/dccstor/bmfm-targets/data/omics/transcriptome/scRNA/finetune\")\n",
    "src_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7aa49e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/dccstor/bmfm-targets/data/omics/transcriptome/scRNA/finetune/AnnCollection')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst_root = src_root / \"AnnCollection\"\n",
    "dst_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7bc638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': PosixPath('/dccstor/bmfm-targets/data/omics/transcriptome/scRNA/finetune/AnnCollection/changepi_scp1884_scp259/litdata_index'),\n",
       " 'data': PosixPath('/dccstor/bmfm-targets/data/omics/transcriptome/scRNA/finetune/AnnCollection/changepi_scp1884_scp259/ALL')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flds = prepare_folders([\n",
    "    (src_root / \"ChangEpi\" / \"processed.h5ad\", \"changepi\"),\n",
    "    (src_root / \"SCP1884\" / \"processed.h5ad\", \"scp1884\"),\n",
    "    (src_root / \"scIBD300K\" / \"processed.h5ad\", \"scp259\"),\n",
    "], dest_root=dst_root)\n",
    "flds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9478e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = flds[\"data\"]\n",
    "index_dir = flds[\"index\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0fcbf",
   "metadata": {},
   "source": [
    "### Reading hda5 files into annotation collection \n",
    "see https://anndata.readthedocs.io/en/latest/tutorials/notebooks/anncollection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93643db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collection = get_ann_collection(input_dir=dataset_dir, join_obs=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af69c562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nUMI</th>\n",
       "      <th>nGene</th>\n",
       "      <th>log10GenesPerUMI</th>\n",
       "      <th>mitoRatio</th>\n",
       "      <th>cells</th>\n",
       "      <th>sample</th>\n",
       "      <th>patient</th>\n",
       "      <th>status</th>\n",
       "      <th>Full_Epi_Clus</th>\n",
       "      <th>TissueLoc</th>\n",
       "      <th>Final_CellType</th>\n",
       "      <th>UMAPfull_1</th>\n",
       "      <th>UMAPfull_2</th>\n",
       "      <th>S.Score</th>\n",
       "      <th>G2M.Score</th>\n",
       "      <th>Phase</th>\n",
       "      <th>split_stratified_Final_CellType</th>\n",
       "      <th>n_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HA01_AC_AAACCCAAGGCTGGAT.1</th>\n",
       "      <td>HA01_AC_AAACCCAAGGCTGGAT-1</td>\n",
       "      <td>2487</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.885507</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>HA01_AC_AAACCCAAGGCTGGAT-1</td>\n",
       "      <td>HA01_AC</td>\n",
       "      <td>HA01</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>7</td>\n",
       "      <td>Colon</td>\n",
       "      <td>TA_2</td>\n",
       "      <td>6.467434</td>\n",
       "      <td>-3.884951</td>\n",
       "      <td>0.494657</td>\n",
       "      <td>0.356172</td>\n",
       "      <td>S</td>\n",
       "      <td>dev</td>\n",
       "      <td>3601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA01_AC_AAACCCAAGTCGGGAT.1</th>\n",
       "      <td>HA01_AC_AAACCCAAGTCGGGAT-1</td>\n",
       "      <td>17224</td>\n",
       "      <td>5053</td>\n",
       "      <td>0.874276</td>\n",
       "      <td>0.117627</td>\n",
       "      <td>HA01_AC_AAACCCAAGTCGGGAT-1</td>\n",
       "      <td>HA01_AC</td>\n",
       "      <td>HA01</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>7</td>\n",
       "      <td>Colon</td>\n",
       "      <td>TA_2</td>\n",
       "      <td>7.663868</td>\n",
       "      <td>-3.298563</td>\n",
       "      <td>-0.027053</td>\n",
       "      <td>0.561948</td>\n",
       "      <td>G2M</td>\n",
       "      <td>train</td>\n",
       "      <td>8112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA01_AC_AAACCCAAGTGAACAT.1</th>\n",
       "      <td>HA01_AC_AAACCCAAGTGAACAT-1</td>\n",
       "      <td>23920</td>\n",
       "      <td>4825</td>\n",
       "      <td>0.841219</td>\n",
       "      <td>0.157609</td>\n",
       "      <td>HA01_AC_AAACCCAAGTGAACAT-1</td>\n",
       "      <td>HA01_AC</td>\n",
       "      <td>HA01</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>5</td>\n",
       "      <td>Colon</td>\n",
       "      <td>EC_3</td>\n",
       "      <td>-0.366386</td>\n",
       "      <td>6.462451</td>\n",
       "      <td>-0.040436</td>\n",
       "      <td>-0.077858</td>\n",
       "      <td>G1</td>\n",
       "      <td>train</td>\n",
       "      <td>6986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA01_AC_AAACCCACAAGCGATG.1</th>\n",
       "      <td>HA01_AC_AAACCCACAAGCGATG-1</td>\n",
       "      <td>1499</td>\n",
       "      <td>743</td>\n",
       "      <td>0.904020</td>\n",
       "      <td>0.314209</td>\n",
       "      <td>HA01_AC_AAACCCACAAGCGATG-1</td>\n",
       "      <td>HA01_AC</td>\n",
       "      <td>HA01</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>6</td>\n",
       "      <td>Colon</td>\n",
       "      <td>GC_sub1</td>\n",
       "      <td>-2.295665</td>\n",
       "      <td>-10.757671</td>\n",
       "      <td>-0.065239</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>G2M</td>\n",
       "      <td>train</td>\n",
       "      <td>2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA01_AC_AAACCCATCTACAGGT.1</th>\n",
       "      <td>HA01_AC_AAACCCATCTACAGGT-1</td>\n",
       "      <td>12209</td>\n",
       "      <td>3337</td>\n",
       "      <td>0.862156</td>\n",
       "      <td>0.147268</td>\n",
       "      <td>HA01_AC_AAACCCATCTACAGGT-1</td>\n",
       "      <td>HA01_AC</td>\n",
       "      <td>HA01</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>5</td>\n",
       "      <td>Colon</td>\n",
       "      <td>EC_3</td>\n",
       "      <td>-1.050888</td>\n",
       "      <td>5.104529</td>\n",
       "      <td>-0.049718</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>G2M</td>\n",
       "      <td>train</td>\n",
       "      <td>5576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA55_TI_TTTGTTGGTAGCCCTG.1</th>\n",
       "      <td>HA55_TI_TTTGTTGGTAGCCCTG-1</td>\n",
       "      <td>3003</td>\n",
       "      <td>1171</td>\n",
       "      <td>0.882389</td>\n",
       "      <td>0.373293</td>\n",
       "      <td>HA55_TI_TTTGTTGGTAGCCCTG-1</td>\n",
       "      <td>HA55_TI</td>\n",
       "      <td>HA55</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>1</td>\n",
       "      <td>Ileum</td>\n",
       "      <td>EC_5</td>\n",
       "      <td>-3.822792</td>\n",
       "      <td>-1.868396</td>\n",
       "      <td>-0.035682</td>\n",
       "      <td>-0.039043</td>\n",
       "      <td>G1</td>\n",
       "      <td>train</td>\n",
       "      <td>3734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA55_TI_TTTGTTGGTCGTTATG.1</th>\n",
       "      <td>HA55_TI_TTTGTTGGTCGTTATG-1</td>\n",
       "      <td>4968</td>\n",
       "      <td>1726</td>\n",
       "      <td>0.875780</td>\n",
       "      <td>0.298309</td>\n",
       "      <td>HA55_TI_TTTGTTGGTCGTTATG-1</td>\n",
       "      <td>HA55_TI</td>\n",
       "      <td>HA55</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>1</td>\n",
       "      <td>Ileum</td>\n",
       "      <td>EC_5</td>\n",
       "      <td>-5.908050</td>\n",
       "      <td>-1.003698</td>\n",
       "      <td>-0.020253</td>\n",
       "      <td>-0.077762</td>\n",
       "      <td>G1</td>\n",
       "      <td>train</td>\n",
       "      <td>4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA55_TI_TTTGTTGGTGCCTATA.1</th>\n",
       "      <td>HA55_TI_TTTGTTGGTGCCTATA-1</td>\n",
       "      <td>4841</td>\n",
       "      <td>2058</td>\n",
       "      <td>0.899187</td>\n",
       "      <td>0.270812</td>\n",
       "      <td>HA55_TI_TTTGTTGGTGCCTATA-1</td>\n",
       "      <td>HA55_TI</td>\n",
       "      <td>HA55</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>1</td>\n",
       "      <td>Ileum</td>\n",
       "      <td>EC_5</td>\n",
       "      <td>-2.018079</td>\n",
       "      <td>1.109709</td>\n",
       "      <td>-0.057198</td>\n",
       "      <td>-0.045764</td>\n",
       "      <td>G1</td>\n",
       "      <td>train</td>\n",
       "      <td>4927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA55_TI_TTTGTTGTCGGACAAG.1</th>\n",
       "      <td>HA55_TI_TTTGTTGTCGGACAAG-1</td>\n",
       "      <td>6660</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.864601</td>\n",
       "      <td>0.383483</td>\n",
       "      <td>HA55_TI_TTTGTTGTCGGACAAG-1</td>\n",
       "      <td>HA55_TI</td>\n",
       "      <td>HA55</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>5</td>\n",
       "      <td>Ileum</td>\n",
       "      <td>EC_3</td>\n",
       "      <td>-0.254203</td>\n",
       "      <td>6.876445</td>\n",
       "      <td>-0.042127</td>\n",
       "      <td>-0.036100</td>\n",
       "      <td>G1</td>\n",
       "      <td>dev</td>\n",
       "      <td>4929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA55_TI_TTTGTTGTCTACTCAT.1</th>\n",
       "      <td>HA55_TI_TTTGTTGTCTACTCAT-1</td>\n",
       "      <td>3821</td>\n",
       "      <td>1450</td>\n",
       "      <td>0.882527</td>\n",
       "      <td>0.243392</td>\n",
       "      <td>HA55_TI_TTTGTTGTCTACTCAT-1</td>\n",
       "      <td>HA55_TI</td>\n",
       "      <td>HA55</td>\n",
       "      <td>NonIBD</td>\n",
       "      <td>1</td>\n",
       "      <td>Ileum</td>\n",
       "      <td>EC_5</td>\n",
       "      <td>-5.489967</td>\n",
       "      <td>-1.390551</td>\n",
       "      <td>-0.038588</td>\n",
       "      <td>-0.086956</td>\n",
       "      <td>G1</td>\n",
       "      <td>train</td>\n",
       "      <td>3611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39023 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Unnamed: 0   nUMI  nGene  \\\n",
       "HA01_AC_AAACCCAAGGCTGGAT.1  HA01_AC_AAACCCAAGGCTGGAT-1   2487   1016   \n",
       "HA01_AC_AAACCCAAGTCGGGAT.1  HA01_AC_AAACCCAAGTCGGGAT-1  17224   5053   \n",
       "HA01_AC_AAACCCAAGTGAACAT.1  HA01_AC_AAACCCAAGTGAACAT-1  23920   4825   \n",
       "HA01_AC_AAACCCACAAGCGATG.1  HA01_AC_AAACCCACAAGCGATG-1   1499    743   \n",
       "HA01_AC_AAACCCATCTACAGGT.1  HA01_AC_AAACCCATCTACAGGT-1  12209   3337   \n",
       "...                                                ...    ...    ...   \n",
       "HA55_TI_TTTGTTGGTAGCCCTG.1  HA55_TI_TTTGTTGGTAGCCCTG-1   3003   1171   \n",
       "HA55_TI_TTTGTTGGTCGTTATG.1  HA55_TI_TTTGTTGGTCGTTATG-1   4968   1726   \n",
       "HA55_TI_TTTGTTGGTGCCTATA.1  HA55_TI_TTTGTTGGTGCCTATA-1   4841   2058   \n",
       "HA55_TI_TTTGTTGTCGGACAAG.1  HA55_TI_TTTGTTGTCGGACAAG-1   6660   2022   \n",
       "HA55_TI_TTTGTTGTCTACTCAT.1  HA55_TI_TTTGTTGTCTACTCAT-1   3821   1450   \n",
       "\n",
       "                            log10GenesPerUMI  mitoRatio  \\\n",
       "HA01_AC_AAACCCAAGGCTGGAT.1          0.885507   0.014073   \n",
       "HA01_AC_AAACCCAAGTCGGGAT.1          0.874276   0.117627   \n",
       "HA01_AC_AAACCCAAGTGAACAT.1          0.841219   0.157609   \n",
       "HA01_AC_AAACCCACAAGCGATG.1          0.904020   0.314209   \n",
       "HA01_AC_AAACCCATCTACAGGT.1          0.862156   0.147268   \n",
       "...                                      ...        ...   \n",
       "HA55_TI_TTTGTTGGTAGCCCTG.1          0.882389   0.373293   \n",
       "HA55_TI_TTTGTTGGTCGTTATG.1          0.875780   0.298309   \n",
       "HA55_TI_TTTGTTGGTGCCTATA.1          0.899187   0.270812   \n",
       "HA55_TI_TTTGTTGTCGGACAAG.1          0.864601   0.383483   \n",
       "HA55_TI_TTTGTTGTCTACTCAT.1          0.882527   0.243392   \n",
       "\n",
       "                                                 cells   sample patient  \\\n",
       "HA01_AC_AAACCCAAGGCTGGAT.1  HA01_AC_AAACCCAAGGCTGGAT-1  HA01_AC    HA01   \n",
       "HA01_AC_AAACCCAAGTCGGGAT.1  HA01_AC_AAACCCAAGTCGGGAT-1  HA01_AC    HA01   \n",
       "HA01_AC_AAACCCAAGTGAACAT.1  HA01_AC_AAACCCAAGTGAACAT-1  HA01_AC    HA01   \n",
       "HA01_AC_AAACCCACAAGCGATG.1  HA01_AC_AAACCCACAAGCGATG-1  HA01_AC    HA01   \n",
       "HA01_AC_AAACCCATCTACAGGT.1  HA01_AC_AAACCCATCTACAGGT-1  HA01_AC    HA01   \n",
       "...                                                ...      ...     ...   \n",
       "HA55_TI_TTTGTTGGTAGCCCTG.1  HA55_TI_TTTGTTGGTAGCCCTG-1  HA55_TI    HA55   \n",
       "HA55_TI_TTTGTTGGTCGTTATG.1  HA55_TI_TTTGTTGGTCGTTATG-1  HA55_TI    HA55   \n",
       "HA55_TI_TTTGTTGGTGCCTATA.1  HA55_TI_TTTGTTGGTGCCTATA-1  HA55_TI    HA55   \n",
       "HA55_TI_TTTGTTGTCGGACAAG.1  HA55_TI_TTTGTTGTCGGACAAG-1  HA55_TI    HA55   \n",
       "HA55_TI_TTTGTTGTCTACTCAT.1  HA55_TI_TTTGTTGTCTACTCAT-1  HA55_TI    HA55   \n",
       "\n",
       "                            status  Full_Epi_Clus TissueLoc Final_CellType  \\\n",
       "HA01_AC_AAACCCAAGGCTGGAT.1  NonIBD              7     Colon           TA_2   \n",
       "HA01_AC_AAACCCAAGTCGGGAT.1  NonIBD              7     Colon           TA_2   \n",
       "HA01_AC_AAACCCAAGTGAACAT.1  NonIBD              5     Colon           EC_3   \n",
       "HA01_AC_AAACCCACAAGCGATG.1  NonIBD              6     Colon        GC_sub1   \n",
       "HA01_AC_AAACCCATCTACAGGT.1  NonIBD              5     Colon           EC_3   \n",
       "...                            ...            ...       ...            ...   \n",
       "HA55_TI_TTTGTTGGTAGCCCTG.1  NonIBD              1     Ileum           EC_5   \n",
       "HA55_TI_TTTGTTGGTCGTTATG.1  NonIBD              1     Ileum           EC_5   \n",
       "HA55_TI_TTTGTTGGTGCCTATA.1  NonIBD              1     Ileum           EC_5   \n",
       "HA55_TI_TTTGTTGTCGGACAAG.1  NonIBD              5     Ileum           EC_3   \n",
       "HA55_TI_TTTGTTGTCTACTCAT.1  NonIBD              1     Ileum           EC_5   \n",
       "\n",
       "                            UMAPfull_1  UMAPfull_2   S.Score  G2M.Score Phase  \\\n",
       "HA01_AC_AAACCCAAGGCTGGAT.1    6.467434   -3.884951  0.494657   0.356172     S   \n",
       "HA01_AC_AAACCCAAGTCGGGAT.1    7.663868   -3.298563 -0.027053   0.561948   G2M   \n",
       "HA01_AC_AAACCCAAGTGAACAT.1   -0.366386    6.462451 -0.040436  -0.077858    G1   \n",
       "HA01_AC_AAACCCACAAGCGATG.1   -2.295665  -10.757671 -0.065239   0.012134   G2M   \n",
       "HA01_AC_AAACCCATCTACAGGT.1   -1.050888    5.104529 -0.049718   0.021243   G2M   \n",
       "...                                ...         ...       ...        ...   ...   \n",
       "HA55_TI_TTTGTTGGTAGCCCTG.1   -3.822792   -1.868396 -0.035682  -0.039043    G1   \n",
       "HA55_TI_TTTGTTGGTCGTTATG.1   -5.908050   -1.003698 -0.020253  -0.077762    G1   \n",
       "HA55_TI_TTTGTTGGTGCCTATA.1   -2.018079    1.109709 -0.057198  -0.045764    G1   \n",
       "HA55_TI_TTTGTTGTCGGACAAG.1   -0.254203    6.876445 -0.042127  -0.036100    G1   \n",
       "HA55_TI_TTTGTTGTCTACTCAT.1   -5.489967   -1.390551 -0.038588  -0.086956    G1   \n",
       "\n",
       "                           split_stratified_Final_CellType  n_counts  \n",
       "HA01_AC_AAACCCAAGGCTGGAT.1                             dev      3601  \n",
       "HA01_AC_AAACCCAAGTCGGGAT.1                           train      8112  \n",
       "HA01_AC_AAACCCAAGTGAACAT.1                           train      6986  \n",
       "HA01_AC_AAACCCACAAGCGATG.1                           train      2427  \n",
       "HA01_AC_AAACCCATCTACAGGT.1                           train      5576  \n",
       "...                                                    ...       ...  \n",
       "HA55_TI_TTTGTTGGTAGCCCTG.1                           train      3734  \n",
       "HA55_TI_TTTGTTGGTCGTTATG.1                           train      4284  \n",
       "HA55_TI_TTTGTTGGTGCCTATA.1                           train      4927  \n",
       "HA55_TI_TTTGTTGTCGGACAAG.1                             dev      4929  \n",
       "HA55_TI_TTTGTTGTCTACTCAT.1                           train      3611  \n",
       "\n",
       "[39023 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.adatas[0].obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d48b7",
   "metadata": {},
   "source": [
    "### Specify the column name for cell type classification for each adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a59ff9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_columnname = [\n",
    "    \"Final_CellType\",\n",
    "    \"Celltype\",\n",
    "    \"celltype\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4463bb",
   "metadata": {},
   "source": [
    "### Make index list for splits from processed h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9469440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of 0 th anndata= 39023\n",
      "length of split (train, dev, test) 31217 3903 3903\n",
      "length of 1 th anndata= 720633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of split (train, dev, test) 576505 72064 72064\n",
      "length of 2 th anndata= 365492\n",
      "length of split (train, dev, test) 292392 36550 36550\n"
     ]
    }
   ],
   "source": [
    "index_base = 0\n",
    "train_index_all = []\n",
    "dev_index_all = []\n",
    "test_index_all = []\n",
    "for i in range(len(collection.adatas)):\n",
    "    print(\"length of\",i,\"th anndata=\",len(collection.adatas[i]))\n",
    "    adata = collection.adatas[i].obs.reset_index()\n",
    "    train_index_ = list(adata[adata['split_stratified_'+cell_type_columnname[i]]=='train'].index)\n",
    "    train_index = [x+index_base for x in train_index_]\n",
    "    dev_index_ = list(adata[adata['split_stratified_'+cell_type_columnname[i]]=='dev'].index)\n",
    "    dev_index = [x+index_base for x in dev_index_]\n",
    "    test_index_ = list(adata[adata['split_stratified_'+cell_type_columnname[i]]=='test'].index)\n",
    "    test_index = [x+index_base for x in test_index_]\n",
    "    print(\"length of split (train, dev, test)\", len(train_index), len(dev_index), len(test_index))\n",
    "    \n",
    "    index_base = index_base + len(adata)\n",
    "\n",
    "    train_index_all = train_index_all + train_index\n",
    "    dev_index_all = dev_index_all +dev_index\n",
    "    test_index_all = test_index_all + test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706e475b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900114, 900114)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_index_all), 31217+576505+292392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcc718d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112517, 112517)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_index_all), 3903+72064+36550"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2ba75",
   "metadata": {},
   "source": [
    "### verification of index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5425d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[365461, 365465, 365473, 365478]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti_ = test_index_[-4:]\n",
    "ti_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11de82be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1125117, 1125121, 1125129, 1125134]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti=test_index[-4:]\n",
    "ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed06dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biosample_id</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>Chem</th>\n",
       "      <th>Site</th>\n",
       "      <th>Type</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>Layer</th>\n",
       "      <th>Celltype</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>organ</th>\n",
       "      <th>organ__ontology_label</th>\n",
       "      <th>disease</th>\n",
       "      <th>disease__ontology_label</th>\n",
       "      <th>batch</th>\n",
       "      <th>n_genes_by_counts</th>\n",
       "      <th>total_counts</th>\n",
       "      <th>total_counts_mt</th>\n",
       "      <th>pct_counts_mt</th>\n",
       "      <th>split_stratified_Celltype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N10_LP_A-GACGAACTGGGACA</th>\n",
       "      <td>N10_LP_A</td>\n",
       "      <td>251</td>\n",
       "      <td>1130</td>\n",
       "      <td>v1</td>\n",
       "      <td>CO</td>\n",
       "      <td>Heal</td>\n",
       "      <td>N10</td>\n",
       "      <td>L</td>\n",
       "      <td>Plasma cells</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON_0001155</td>\n",
       "      <td>colon</td>\n",
       "      <td>PATO_0000461</td>\n",
       "      <td>normal</td>\n",
       "      <td>CO_IMM.scp</td>\n",
       "      <td>251</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.087452</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        biosample_id  n_genes  n_counts Chem Site  Type  \\\n",
       "index                                                                     \n",
       "N10_LP_A-GACGAACTGGGACA     N10_LP_A      251      1130   v1   CO  Heal   \n",
       "\n",
       "                        donor_id Layer      Celltype      sex  ...  \\\n",
       "index                                                          ...   \n",
       "N10_LP_A-GACGAACTGGGACA      N10     L  Plasma cells  unknown  ...   \n",
       "\n",
       "                                  organ organ__ontology_label       disease  \\\n",
       "index                                                                         \n",
       "N10_LP_A-GACGAACTGGGACA  UBERON_0001155                 colon  PATO_0000461   \n",
       "\n",
       "                        disease__ontology_label       batch n_genes_by_counts  \\\n",
       "index                                                                           \n",
       "N10_LP_A-GACGAACTGGGACA                  normal  CO_IMM.scp               251   \n",
       "\n",
       "                        total_counts total_counts_mt pct_counts_mt  \\\n",
       "index                                                                \n",
       "N10_LP_A-GACGAACTGGGACA       1052.0            43.0      4.087452   \n",
       "\n",
       "                         split_stratified_Celltype  \n",
       "index                                               \n",
       "N10_LP_A-GACGAACTGGGACA                        dev  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.adatas[1][ti_[3]].obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b7e798c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "N10_LP_A-GACGAACTGGGACA    dev\n",
       "Name: split_stratified_Celltype, dtype: category\n",
       "Categories (1, object): ['dev']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.adatas[1][ti_[3]].obs['split_stratified_Celltype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ad0961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['N10_LP_A-GACGAACTGGGACA'], dtype='object', name='index')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.adatas[1][ti_[3]].obs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2e7bda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['N110.LPB.TGTCCCACATTAGCCA'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[ti[3]].obs['dataset'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "878db5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"celltype\" in collection.obs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402261c3",
   "metadata": {},
   "source": [
    "### Make folder for LitData index and create (test, dev) subfolders with LitData indices\n",
    "\n",
    "Function build_index takes **index** parameter, an iterable such as Python generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42d007c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_index(\n",
    "    output_dir=index_dir / \"train\",\n",
    "    index = train_index_all,\n",
    "    chunk_size = 5000\n",
    ")\n",
    "build_index(\n",
    "    output_dir=index_dir / \"dev\",\n",
    "    index = dev_index_all,\n",
    "    chunk_size = 5000\n",
    ")\n",
    "build_index(\n",
    "    output_dir=index_dir / \"test\",\n",
    "    index = test_index_all,\n",
    "    chunk_size = 5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af9ff1",
   "metadata": {},
   "source": [
    "# Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0fc4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmfm_targets import config\n",
    "from bmfm_targets.datasets.anncollection import AnnCollectionDataModule\n",
    "from bmfm_targets.tokenization import get_gene2vec_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c2c8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bmfm_targets.datasets.anncollection' from '/dccstor/bmfm-targets/users/a1kosugi/gsetests/bmfm/bmfm_targets/datasets/anncollection/__init__.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import bmfm_targets.datasets.anncollection\n",
    "\n",
    "reload(bmfm_targets.datasets.anncollection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98453e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bmfm_targets.datasets.anncollection.anncollection_dataset' from '/dccstor/bmfm-targets/users/a1kosugi/gsetests/bmfm/bmfm_targets/datasets/anncollection/anncollection_dataset.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import bmfm_targets.datasets.anncollection.anncollection_dataset\n",
    "\n",
    "reload(bmfm_targets.datasets.anncollection.anncollection_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57e5ad",
   "metadata": {},
   "source": [
    "### Helper function that is needed only for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d376c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene2vec_fields():\n",
    "    gene2vec_field_dicts = [\n",
    "        {\n",
    "            \"field_name\": \"genes\",\n",
    "            \"pretrained_embedding\": None,\n",
    "            \"is_masked\": False,\n",
    "            \"vocab_update_strategy\": \"static\",\n",
    "        },\n",
    "        {\n",
    "            \"field_name\": \"expressions\",\n",
    "            \"pretrained_embedding\": None,\n",
    "            \"is_masked\": True,\n",
    "            \"vocab_update_strategy\": \"static\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    gene2vec_fields = [config.FieldInfo(**fd) for fd in gene2vec_field_dicts]\n",
    "    tokenizer = get_gene2vec_tokenizer()\n",
    "    for field in gene2vec_fields:\n",
    "        field.update_vocab_size(tokenizer)\n",
    "    return gene2vec_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1083e2",
   "metadata": {},
   "source": [
    "### Parameters that normally have to be set in yaml file (see PanglaoDB yaml files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fa93941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "    \"dataset_dir\": dataset_dir,\n",
    "    \"index_dir\": index_dir,\n",
    "    \"label_columns\": [\"Celltype\", \"celltype\", \"Final_CellType\"],\n",
    "}\n",
    "tokenizer = get_gene2vec_tokenizer()\n",
    "pars = {\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"batch_size\": 2,\n",
    "    \"fields\": gene2vec_fields(),\n",
    "    \"num_workers\": 8,\n",
    "    \"mlm\": False,\n",
    "    \"collation_strategy\": \"sequence_classification\",\n",
    "    \"dataset_kwargs\": dataset_kwargs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32432a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n",
      "/u/a1kosugi/.conda/envs/bmfm_til/lib/python3.10/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "datamodule = AnnCollectionDataModule(**pars)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef1b988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Celltype': {'Activated fibroblasts CCL19 ADAMADEC1': 0,\n",
       "  'B cells': 1,\n",
       "  'B cells AICDA LRMP': 2,\n",
       "  'Cycling cells': 3,\n",
       "  'DC1': 4,\n",
       "  'DC2 CD1D': 5,\n",
       "  'DC2 CD1D-': 6,\n",
       "  'Endothelial cells CA4 CD36': 7,\n",
       "  'Endothelial cells CD36': 8,\n",
       "  'Endothelial cells DARC': 9,\n",
       "  'Endothelial cells LTC4S SEMA3G': 10,\n",
       "  'Enterochromaffin cells': 11,\n",
       "  'Enterocytes BEST4': 12,\n",
       "  'Enterocytes CA1 CA2 CA4-': 13,\n",
       "  'Enterocytes TMIGD1 MEP1A': 14,\n",
       "  'Enterocytes TMIGD1 MEP1A GSTA1': 15,\n",
       "  'Enteroendocrine cells': 16,\n",
       "  'Epithelial Cycling cells': 17,\n",
       "  'Epithelial HBB HBA': 18,\n",
       "  'Epithelial cells METTL12 MAFB': 19,\n",
       "  'Fibroblasts ADAMDEC1': 20,\n",
       "  'Fibroblasts KCNN3 LY6H': 21,\n",
       "  'Fibroblasts NPY SLITRK6': 22,\n",
       "  'Fibroblasts SFRP2 SLPI': 23,\n",
       "  'Fibroblasts SMOC2 PTGIS': 24,\n",
       "  'Glial cells': 25,\n",
       "  'Goblet cells MUC2 TFF1': 26,\n",
       "  'Goblet cells MUC2 TFF1-': 27,\n",
       "  'Goblet cells SPINK4': 28,\n",
       "  'IELs ID3 ENTPD1': 29,\n",
       "  'ILCs': 30,\n",
       "  'Immune Cycling cells': 31,\n",
       "  'Inflammatory fibroblasts IL11 CHI3L1': 32,\n",
       "  'L cells': 33,\n",
       "  'Lymphatics': 34,\n",
       "  'Macrophages': 35,\n",
       "  'Macrophages CCL3 CCL4': 36,\n",
       "  'Macrophages CXCL9 CXCL10': 37,\n",
       "  'Macrophages LYVE1': 38,\n",
       "  'Macrophages Metallothionein': 39,\n",
       "  'Macrophages PLA2G2D': 40,\n",
       "  'Mast cells': 41,\n",
       "  'Mature DCs': 42,\n",
       "  'Monocytes CHI3L1 CYP27A1': 43,\n",
       "  'Monocytes HBB': 44,\n",
       "  'Monocytes S100A8 S100A9': 45,\n",
       "  'Myofibroblasts GREM1 GREM2': 46,\n",
       "  'Myofibroblasts HHIP NPNT': 47,\n",
       "  'NK cells KLRF1 CD3G-': 48,\n",
       "  'NK-like cells ID3 ENTPD1': 49,\n",
       "  'Neutrophils S100A8 S100A9': 50,\n",
       "  'Paneth cells': 51,\n",
       "  'Pericytes HIGD1B STEAP4': 52,\n",
       "  'Pericytes RERGL NTRK2': 53,\n",
       "  'Plasma cells': 54,\n",
       "  'Stem cells OLFM4': 55,\n",
       "  'Stem cells OLFM4 GSTA1': 56,\n",
       "  'Stem cells OLFM4 LGR5': 57,\n",
       "  'Stem cells OLFM4 PCNA': 58,\n",
       "  'Stromal Cycling cells': 59,\n",
       "  'T cells CD4 FOSB': 60,\n",
       "  'T cells CD4 IL17A': 61,\n",
       "  'T cells CD8': 62,\n",
       "  'T cells CD8 KLRG1': 63,\n",
       "  'T cells Naive CD4': 64,\n",
       "  'T cells OGT': 65,\n",
       "  'Tregs': 66,\n",
       "  'Tuft cells': 67},\n",
       " 'celltype': {'Best4+ Enterocytes': 0,\n",
       "  'CD4+ Activated Fos-hi': 1,\n",
       "  'CD4+ Activated Fos-lo': 2,\n",
       "  'CD4+ Memory': 3,\n",
       "  'CD4+ PD1+': 4,\n",
       "  'CD69+ Mast': 5,\n",
       "  'CD69- Mast': 6,\n",
       "  'CD8+ IELs': 7,\n",
       "  'CD8+ IL17+': 8,\n",
       "  'CD8+ LP': 9,\n",
       "  'Cycling B': 10,\n",
       "  'Cycling Monocytes': 11,\n",
       "  'Cycling T': 12,\n",
       "  'Cycling TA': 13,\n",
       "  'DC1': 14,\n",
       "  'DC2': 15,\n",
       "  'Endothelial': 16,\n",
       "  'Enterocyte Progenitors': 17,\n",
       "  'Enterocytes': 18,\n",
       "  'Enteroendocrine': 19,\n",
       "  'Follicular': 20,\n",
       "  'GC': 21,\n",
       "  'Glia': 22,\n",
       "  'Goblet': 23,\n",
       "  'ILCs': 24,\n",
       "  'Immature Enterocytes 1': 25,\n",
       "  'Immature Enterocytes 2': 26,\n",
       "  'Immature Goblet': 27,\n",
       "  'Inflammatory Fibroblasts': 28,\n",
       "  'Inflammatory Monocytes': 29,\n",
       "  'M cells': 30,\n",
       "  'MT-hi': 31,\n",
       "  'Macrophages': 32,\n",
       "  'Microvascular': 33,\n",
       "  'Myofibroblasts': 34,\n",
       "  'NKs': 35,\n",
       "  'Pericytes': 36,\n",
       "  'Plasma': 37,\n",
       "  'Post-capillary Venules': 38,\n",
       "  'RSPO3+': 39,\n",
       "  'Secretory TA': 40,\n",
       "  'Stem': 41,\n",
       "  'TA 1': 42,\n",
       "  'TA 2': 43,\n",
       "  'Tregs': 44,\n",
       "  'Tuft': 45,\n",
       "  'WNT2B+ Fos-hi': 46,\n",
       "  'WNT2B+ Fos-lo 1': 47,\n",
       "  'WNT2B+ Fos-lo 2': 48,\n",
       "  'WNT5B+ 1': 49,\n",
       "  'WNT5B+ 2': 50},\n",
       " 'Final_CellType': {'B-Cell': 0,\n",
       "  'BEST4+': 1,\n",
       "  'Clus12': 2,\n",
       "  'DeepCrypt': 3,\n",
       "  'EC_1': 4,\n",
       "  'EC_2': 5,\n",
       "  'EC_3': 6,\n",
       "  'EC_4': 7,\n",
       "  'EC_5': 8,\n",
       "  'EEC_1': 9,\n",
       "  'EEC_2': 10,\n",
       "  'GC': 11,\n",
       "  'GC_sub1': 12,\n",
       "  'GC_sub2': 13,\n",
       "  'SC': 14,\n",
       "  'T-Cell': 15,\n",
       "  'TA_1': 16,\n",
       "  'TA_2': 17,\n",
       "  'TA_3': 18,\n",
       "  'Tuft': 19}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42ad673",
   "metadata": {},
   "source": [
    "## Look at a sample in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8114607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=datamodule.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d162049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Celltype': nan,\n",
       " 'celltype': nan,\n",
       " 'Final_CellType': 'EC_3',\n",
       " 'cell_name': 'HA01_AC_AAACCCAAGTGAACAT.1'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = dataset[1]\n",
    "ds.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8742b375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Celltype': nan,\n",
       " 'celltype': nan,\n",
       " 'Final_CellType': 'SC',\n",
       " 'cell_name': 'HA01_AC_CTTACCGCAATCGAAA.1'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1000].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1b163",
   "metadata": {},
   "source": [
    "## Look at a collation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59cb90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = datamodule.train_dataloader()\n",
    "itr = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30508238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: HA01_AC_AAACCCAAGTCGGGAT.1 - HA01_AC_AAACCCAAGTCGGGAT.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: HA01_AC_AAACCCAAGTGAACAT.1 - N128400_L-CAACCTCCAAACCACT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    item = next(itr)\n",
    "    c1 = dataset[i].metadata[\"cell_name\"]\n",
    "    c2 = item[\"cell_names\"][0]\n",
    "    print(f\"{c1 == c2}: {c1} - {c2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f34ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: HA01_AC_AAACCCAAGTGAACAT.1 - N128400_L-CAACCTCCAAACCACT\n"
     ]
    }
   ],
   "source": [
    "print(f\"{c1 == c2}: {c1} - {c2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b43bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    3,  8248,     0,  ...,  4761,  8316,     1],\n",
      "         [    3,     7,     6,  ...,     6,     7,     1]],\n",
      "\n",
      "        [[    3, 19247, 20318,  ..., 22585,  8066,     1],\n",
      "         [    3,     6,     7,  ...,     6,     6,     1]]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'cell_names': ['HA01_AC_AAACCCAAGTCGGGAT.1', 'HA01_AC_AAACCCAAGTGAACAT.1'], 'labels': {'Celltype': tensor([-100, -100]), 'celltype': tensor([-100, -100]), 'Final_CellType': tensor([17,  6])}}\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = datamodule.train_dataloader()\n",
    "item = next(iter(train_dataloader))\n",
    "print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmfm_til",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
