{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e18538",
   "metadata": {},
   "source": [
    "# How it works\n",
    "\n",
    "**AnnCollectionDataset** directly reads h5ad files through [AnnCollection](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/anncollection.html) and serve data using [LitData](https://github.com/Lightning-AI/litdata) frontend. To use dataset, we first need to prepare dataset index folder that has multiple splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37610cb",
   "metadata": {},
   "source": [
    "# Building LitData index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb9a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/vgurev/miniforge3/envs/bmfm-targets/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from bmfm_targets.datasets.anncollection import get_ann_collection\n",
    "from bmfm_targets.datasets.data_conversion.litdata_indexing import build_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec56d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/dccstor/bmfm-targets/data/omics/transcriptome/bulkRNA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0fcbf",
   "metadata": {},
   "source": [
    "### Reading hda5 files into annotation collection \n",
    "see https://anndata.readthedocs.io/en/latest/tutorials/notebooks/anncollection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93643db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(root_dir, \"ALL\")\n",
    "collection = get_ann_collection(input_dir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402261c3",
   "metadata": {},
   "source": [
    "### Make folder for LitData index and create (test, dev) subfolders with LitData indices\n",
    "\n",
    "Function build_index takes **index** parameter, an iterable such as Python generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc79c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dir = os.path.join(root_dir, \"bulkRNA_litdata_index\")\n",
    "os.mkdir(index_dir)\n",
    "n_cells = collection.n_obs\n",
    "n_train_split = int(n_cells * 0.9)\n",
    "\n",
    "build_index(\n",
    "    output_dir=os.path.join(index_dir, \"train\"),\n",
    "    index = range(0, n_train_split),\n",
    "    chunk_size = 5000\n",
    ")\n",
    "build_index(\n",
    "    output_dir=os.path.join(index_dir, \"dev\"),\n",
    "    index = range(n_train_split, n_cells),\n",
    "    chunk_size = 5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af9ff1",
   "metadata": {},
   "source": [
    "# Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fc4385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmfm_targets import config\n",
    "from bmfm_targets.datasets.annotated_data import AnnCollectionDataModule\n",
    "from bmfm_targets.tokenization import get_gene2vec_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57e5ad",
   "metadata": {},
   "source": [
    "### Helper function that is needed only for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d376c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene2vec_fields():\n",
    "    gene2vec_field_dicts = [\n",
    "        {\n",
    "            \"field_name\": \"genes\",\n",
    "            \"pretrained_embedding\": None,\n",
    "            \"is_masked\": False,\n",
    "            \"vocab_update_strategy\": \"static\",\n",
    "        },\n",
    "        {\n",
    "            \"field_name\": \"expressions\",\n",
    "            \"pretrained_embedding\": None,\n",
    "            \"is_masked\": True,\n",
    "            \"vocab_update_strategy\": \"static\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    gene2vec_fields = [config.FieldInfo(**fd) for fd in gene2vec_field_dicts]\n",
    "    tokenizer = get_gene2vec_tokenizer()\n",
    "    for field in gene2vec_fields:\n",
    "        field.update_vocab_size(tokenizer)\n",
    "    return gene2vec_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1083e2",
   "metadata": {},
   "source": [
    "### Parameters that normally have to be set in yaml file (see PanglaoDB yaml files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fa93941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "    \"dataset_dir\": dataset_dir,\n",
    "    \"index_dir\": index_dir \n",
    "}\n",
    "tokenizer = get_gene2vec_tokenizer()\n",
    "pars = {\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"batch_size\": 2,\n",
    "    \"fields\": gene2vec_fields(),\n",
    "    \"num_workers\": 0,\n",
    "    \"mlm\": True,\n",
    "    \"collation_strategy\": \"language_modeling\",\n",
    "    \"dataset_kwargs\": dataset_kwargs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32432a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[    3,     0,  7402,  ...,  5681,  9529,     1],\n",
      "         [    3,     4,     0,  ...,    13,     0,     1]],\n",
      "\n",
      "        [[    3,     0,  7402,  ...,  9826, 22087,     1],\n",
      "         [    3,    13,     0,  ...,     0,     0,     1]]]), 'labels': tensor([[[-100,    0, -100,  ...,    0, -100, -100]],\n",
      "\n",
      "        [[-100, -100, -100,  ..., -100, -100, -100]]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "datamodule = AnnCollectionDataModule(**pars)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "item = next(iter(train_dataloader))\n",
    "print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
