{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5e5376",
   "metadata": {},
   "source": [
    "# Zero-shot cell type annotation (For Power Users)\n",
    "\n",
    "NB - we recommend users interface with the model using the CLI and yaml configs. \n",
    "\n",
    "Assinging cell type annotations is an import and time consuming part of single-cell analysis using `biomed-multi-omic` for cell type annotation. BMFM-RNA simplifies this process by not only performing the cell-type annotation but also the preprocessing and visualisation through the embeddings created by the model.\n",
    "\n",
    "In this tutorial we approach this from a power user's perspective, interfacing the with the code-base directly and setting up the relevant pytorch-lightening modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbf2cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import scanpy as sc\n",
    "import torch\n",
    "\n",
    "from bmfm_targets import config\n",
    "from bmfm_targets.evaluation.utils import check_gpu, get_label_map, merge_bmfm_adata\n",
    "from bmfm_targets.tasks.task_utils import (\n",
    "    instantiate_module_from_checkpoint,\n",
    "    make_trainer_for_task,\n",
    "    predict,\n",
    ")\n",
    "from bmfm_targets.tokenization import load_tokenizer\n",
    "from bmfm_targets.training.modules import DataModule\n",
    "\n",
    "DEVICE = check_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985445bb",
   "metadata": {},
   "source": [
    "## Load Example Data\n",
    "\n",
    "To demostrate the BMFM-RNAs abilites, we use the PBMC data created by 10X Genomics (dataset can be downloaded [here](https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k)). This dataset is created of 3k PBMCs from a Healthy Donor. The raw data will be used as the input, but we will also extract the cell type annotation from the legacy scanpy workflow as a comparison between the BMFM and classical scRNA-seq analysis. \n",
    "\n",
    "For more information about how the data was preprocessing please visit scanpy's tutorial [here](https://scanpy.readthedocs.io/en/1.11.x/tutorials/basics/clustering-2017.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017d7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw PBMC3k data\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get PMBC3k raw dataset\n",
    "adata = sc.datasets.pbmc3k()\n",
    "\n",
    "# Extract reference data for later downstream comparison\n",
    "reference_adata = sc.datasets.pbmc3k_processed()\n",
    "reference_labels = reference_adata.obs[[\"louvain\"]]\n",
    "reference_obs_index = reference_adata.obs.index.tolist()\n",
    "reference_vars_index = reference_adata.var.index.tolist()\n",
    "\n",
    "adata = adata[reference_obs_index, reference_vars_index]\n",
    "adata.write(\"data/pbmc3k_raw.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16bf4f",
   "metadata": {},
   "source": [
    "Create results directory to save predictions and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3685c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef40972",
   "metadata": {},
   "source": [
    "## Load checkpoint\n",
    "\n",
    "To load a model checkpoint, you can either provide a local path or a model id from the Hugging Face model repository: https://huggingface.co/ibm-research \n",
    "\n",
    "The model used for this tutorial: [ibm-research/bmfm.rna.bert.110m.wced.multitask.v1](https://huggingface.co/ibm-research/biomed.rna.bert.110m.wced.v1)\n",
    "\n",
    "To get the model loaded you can use either:\n",
    "1. Local Path: download the model checkpoints and tokenizer from huggingface\n",
    "2. Hugging Face Repo: using  `ibm-research/bmfm.rna.bert.110m.wced.multitask.v1`\n",
    "\n",
    "The model checkpoint has the following keys:\n",
    "\n",
    "- `epoch`: This key stores the current epoch number during training.\n",
    "- `global_step`: This key stores the current global step number during training.\n",
    "- `pytorch-lightning_version`: This key stores the version of PyTorch Lightning used to save the checkpoint.\n",
    "- `state_dict`: This key stores the model's state dictionary, which contains the model's parameters (weights and biases).\n",
    "- `loops`: This key stores the list of training loops that were executed during the training process.\n",
    "- `callbacks`: This key stores the list of callbacks that were executed during the training process.\n",
    "- `optimizer_states`: This key stores the optimizer's state dictionary, which includes the optimizer's internal state, such as the current step, momentum, and learning rate.\n",
    "- `lr_schedulers`: This key stores the learning rate scheduler's state dictionary, which includes the scheduler's internal state, such as the current epoch or step.\n",
    "- `MixedPrecision`: This key stores the mixed precision settings used during training, if any.\n",
    "- `hparams_name`: This key stores the name of the hyperparameter configuration used for training.\n",
    "- `hyper_parameters`: This key stores a dictionary of hyperparameters such as 'model_config', 'trainer_config', and 'label_dict'. \n",
    "\n",
    "\n",
    "In both cases, the model's configuration will be automatically loaded. If you want to use a specific configuration, you can provide these parameters later in the `task_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d417648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint locally\n",
    "model_path = Path(\"wced_1024_multitask\")\n",
    "checkpoint_path = model_path / \"last.ckpt\"\n",
    "\n",
    "cpkt = torch.load(\n",
    "    checkpoint_path,\n",
    "    map_location=torch.device(DEVICE),\n",
    "    weights_only=False,\n",
    ")\n",
    "\n",
    "label_dict = cpkt[\"hyper_parameters\"][\"label_dict\"]\n",
    "model_config = cpkt[\"hyper_parameters\"][\"model_config\"]\n",
    "\n",
    "tokenizer = load_tokenizer(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee546cb",
   "metadata": {},
   "source": [
    "## Create Data, Trainer and Task Configs\n",
    "\n",
    "Once the model checkpoint and tokenizer have been loaded, you will need to setup the data loader for your data. The easiest way to load your data is to save your data as an H5AD object and then provide the path to the data in the `dataset_kwargs` under the key `processed_data_source`. \n",
    "\n",
    "Importantly, as we are using the checkpoint for WCED model (`ibm-research/bmfm.rna.bert.110m.wced.multitask.v1`) you will need to ensure that `adata.X` is raw counts. The data module will then handle any transformation for you including limited the genes to protein coding genes only.\n",
    "\n",
    "Finally, as we want to perform zeroshot, we will need to setup the our data module in predict model by using `data_module.setup(\"predict\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a20631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "str arguments for `pad_zero_expression_strategy` are deprecated\n",
      "batch_wise -> {'strategy': 'batch_wise'}\n"
     ]
    }
   ],
   "source": [
    "data_module = DataModule(\n",
    "    data_dir=\"data\",\n",
    "    transform_datasets=False,\n",
    "    tokenizer=tokenizer,\n",
    "    fields=model_config.fields,\n",
    "    limit_genes=\"protein_coding\",\n",
    "    mlm=False,\n",
    "    collation_strategy=\"multitask\",\n",
    "    batch_size=20,\n",
    "    pad_zero_expression_strategy=\"batch_wise\",\n",
    "    dataset_kwargs={\n",
    "        \"processed_data_source\": \"data/pbmc3k_raw.h5ad\",\n",
    "        \"expose_zeros\": \"all\",\n",
    "    },\n",
    "    transform_kwargs={},\n",
    "    num_workers=1,\n",
    "    log_normalize_transform=True,\n",
    ")\n",
    "data_module.setup(\"predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c2f98",
   "metadata": {},
   "source": [
    "Next we need to set up the trainer and task configs.\n",
    "\n",
    "The trainer config will need to be provided any of the labels you want to predict under the `losses` parameter. In this case we are predicting `cell_type`. However, the multitask model can also predict other labels such as `tissue` and `tissue_general`. For a full is of losses you can inspect the model's checkpoint using: \n",
    "```python \n",
    "cpkt[\"hyper_parameters\"][\"trainer_config\"].losses\n",
    "```\n",
    "\n",
    "The task config needs to be provided with the model checkpoint path we created eariler. The DEVICE in this case is set based on the detected hardware on your machine. Finally, we create the pytorch lighting \n",
    "\n",
    "*NB: `\"16-mixed\"` if using CUDA rather than `32` on CPU or MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf6ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer_config = config.TrainerConfig(\n",
    "    losses=[{\"label_column_name\": \"cell_type\"}], batch_size=20\n",
    ")\n",
    "\n",
    "task_config = config.PredictTaskConfig(\n",
    "    checkpoint=str(checkpoint_path),\n",
    "    default_root_dir=\".\",\n",
    "    precision=\"32\",  # \"16-mixed\" if using CUDA rather than CPU or MPS\n",
    "    accelerator=DEVICE,\n",
    "    output_embeddings=True,\n",
    "    output_predictions=True,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True,\n",
    "    callbacks=[],\n",
    ")\n",
    "\n",
    "pl_trainer = make_trainer_for_task(task_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72acc295",
   "metadata": {},
   "source": [
    "Initialize model from checkpoint with task config, data module, model config and the trainer config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86216351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tie weights not supported for this model\n"
     ]
    }
   ],
   "source": [
    "pl_module = instantiate_module_from_checkpoint(\n",
    "    task_config, data_module, model_config, trainer_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee66d63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmfm_targets.training.modules.multitask_modeling.MultiTaskTrainingModule"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pl_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46a30f",
   "metadata": {},
   "source": [
    "## Run predict\n",
    "\n",
    "How the data module, task config, model config and tranier config have been instantiated to a MultiTaskTrainingModule.\n",
    "\n",
    "Then we can use the `predict` function with the trainer, MultiTaskTrainingModule and data module to perform our zero-shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705a4812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattmadgwick/miniforge3/envs/bmfm-dev/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b14f505d440416ca83344b2ab0d07b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "results = predict(\n",
    "    pl_trainer=pl_trainer, pl_module=pl_module, pl_data_module=data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7214a",
   "metadata": {},
   "source": [
    "The complete mapping dictionary of the label codes to the actual cell label names can be converted using the `get_label_map` helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e61189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(453, 'luminal epithelial cell of mammary gland')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = get_label_map(key=\"cell_type\", predictions=results, label_dict=label_dict)\n",
    "\n",
    "# Show the first few labels mapped to cell-types\n",
    "list(label_map.items())[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5de72",
   "metadata": {},
   "source": [
    "## Save adata object\n",
    "\n",
    "Finally, you can save the adata object with the cell types and BMFM embedding using the scanpy's `.write_h5ad()` and save the results from the model as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe97571",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X_umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adata_merged \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_bmfm_adata\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_adata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m adata_merged\n",
      "File \u001b[0;32m~/Documents/Projects/bmfm-targets/bmfm_targets/evaluation/utils.py:265\u001b[0m, in \u001b[0;36mmerge_bmfm_adata\u001b[0;34m(bmfm_adata, reference_adata)\u001b[0m\n\u001b[1;32m    263\u001b[0m bmfm_adata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_bmfm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bmfm_adata\u001b[38;5;241m.\u001b[39mX\n\u001b[1;32m    264\u001b[0m reference_adata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_bmfm\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bmfm_adata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_bmfm\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 265\u001b[0m reference_adata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_umap\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbmfm_adata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobsm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_umap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    266\u001b[0m reference_adata\u001b[38;5;241m.\u001b[39mobs \u001b[38;5;241m=\u001b[39m reference_adata\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    267\u001b[0m     bmfm_adata\u001b[38;5;241m.\u001b[39mobs, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, lsuffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_bmfm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reference_adata\n",
      "File \u001b[0;32m~/miniforge3/envs/bmfm-dev/lib/python3.11/site-packages/anndata/_core/aligned_mapping.py:211\u001b[0m, in \u001b[0;36mAlignedActual.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Value:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X_umap'"
     ]
    }
   ],
   "source": [
    "adata_merged = merge_bmfm_adata(adata, reference_adata)\n",
    "adata_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe9105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_merged.write_h5ad(results_dir / \"bmfm_pbmc3k.h5ad\")\n",
    "with open(results_dir / \"bmfm_pbmc3k_results.pkl\", \"wb\") as rf:\n",
    "    pickle.dump(results, rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmfm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
